version: '3.8'

services:
  backend-api:
    container_name: backend-api
    build:
      context: .
      dockerfile: ./src/backend_api/Dockerfile
    depends_on:
      - db-timescale
    ports:
      - "80:80"
    environment:
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASS: ${DB_PASS}
      DB_POOL_SIZE: ${DB_POOL_SIZE}
      PYTHONPATH: /app/
      ROOT_DIR: /app/
  notebook:
    container_name: notebook
    build:
      context: .
      dockerfile: ./src/backend_api/Dockerfile-notebook
    depends_on:
      - backend-api
      - db-timescale
      - spark-master
      - kafka-broker
    ports:
      - "8888:8888"
    environment:
      DB_HOST: db-timescale
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASS: ${DB_PASS}
      DB_POOL_SIZE: ${DB_POOL_SIZE}
      PYTHONPATH: /app/
    volumes:
      - ./notebook:/opt/notebooks
  db-timescale:
    container_name: db-timescale
    image: timescale/timescaledb:latest-pg12
    restart: always
    ports:
      - "5432:5432"
    environment:
      PGUSER: ${DB_USER}  # for health check
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - ./src/db_timescale/storage:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
  # spark
  spark-master:
    build:
      context: .
      dockerfile: ./src/backend_pipeline/spark/Dockerfile
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      HOSTNAME: spark-master
      SPARK_MODE: master
      SPARK_LOCAL_IP: 0.0.0.0
      # - SPARK_WORKER_CORES=2
      # - SPARK_WORKER_MEMORY=500m
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      # - JAVA_HOME: /opt/bitnami/java
      # - SPARK_HOME: /opt/bitnami/spark
      DB_HOST: db-timescale
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASS: ${DB_PASS}
      DB_POOL_SIZE: ${DB_POOL_SIZE}
    volumes:
      - ./notebook:/opt/notebooks
    ports:
      - '8080:8080'
      - '7077:7077'
  spark-worker-1:
    build:
      context: .
      dockerfile: ./src/backend_pipeline/spark/Dockerfile
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      DB_HOST: db-timescale
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASS: ${DB_PASS}
      DB_POOL_SIZE: ${DB_POOL_SIZE}
    volumes:
      - ./notebook:/opt/notebooks
  # grafana
  frontend:
    container_name: frontend
    image: grafana/grafana:latest
    depends_on:
      db-timescale:
        condition: service_healthy
    ports:
        - 3000:3000
    volumes:
        - ./src/frontend/data:/var/lib/grafana
        - ./src/frontend/config:/etc/grafana/
        - ./src/frontend/log:/var/log/grafana
        - ./src/frontend/provisioning:/etc/grafana/provisioning
    environment:
      # grafana internal vars
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: db-timescale:${DB_PORT}
      GF_DATABASE_NAME: ${DB_NAME}
      GF_DATABASE_USER: ${DB_USER}
      GF_DATABASE_PASSWORD: ${DB_PASS}
      GF_DATABASE_SSL_MODE: disable
      #datasource vars
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASS: ${DB_PASS}

  # kafka
  kafka-zookeeper:
    image: confluentinc/cp-zookeeper:6.2.1
    hostname: zookeeper
    container_name: kafka-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./src/backend_pipeline/zookeeper/storage:/var/lib/zookeeper/

  kafka-broker:
    image: confluentinc/cp-kafka:6.2.1
    hostname: broker
    container_name: kafka-broker
    depends_on:
      - kafka-zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - ./src/backend_pipeline/kafka/conf:/etc/kafka
      - ./src/backend_pipeline/kafka/data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "broker:9092"]
      interval: 30s
      timeout: 30s
      retries: 5

  kafka-setup:
    # A workaround used to set up topic.
    # Example: https://github.com/confluentinc/examples/blob/5.1.1-post/microservices-orders/docker-compose.yml#L182-L215
    image: confluentinc/cp-kafka:6.2.1
    hostname: kafka-setup
    container_name: kafka-setup
    depends_on:
      kafka-broker:
        condition: service_healthy
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker:9092 1 20 && \
                       kafka-topics --create --topic us-election --bootstrap-server broker:9092 \
                          --replication-factor 1 --partitions 1 -if-not-exists
                      '"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: 99999
      KAFKA_ZOOKEEPER_CONNECT: ignored
